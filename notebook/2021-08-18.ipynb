{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # python community standard \n",
    "\n",
    "filename = \"../data/raw/原始資料.xlsx\"\n",
    "\n",
    "xls = pd.ExcelFile(filename, engine='openpyxl')\n",
    "df = pd.read_excel(xls, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['代號', '數量']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first 20 rows\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data with whose <代號 A> in the dataframe\n",
    "\n",
    "df_A = df[df['代號']=='A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum 數量 for each 代號 each 交易日期\n",
    "# Make 交易日期 from index to column\n",
    "\n",
    "df.reset_index(inplace=True)  # or df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum = df.groupby(['代號', '交易日期'], as_index=False)['數量'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum[df_sum['代號']=='A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify unique 代號\n",
    "import numpy as np\n",
    "\n",
    "unique_product_code = np.unique(df_sum['代號'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_product_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df_list = []  # python list\n",
    "\n",
    "for code in unique_product_code:\n",
    "    product_df_list.append(df_sum[df_sum['代號']==code])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us see what we have in the list\n",
    "\n",
    "product_df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df_list = []\n",
    "\n",
    "for code in unique_product_code:\n",
    "    product_df_list.append(df_sum[df_sum['代號']==code].set_index(\"交易日期\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all the 數量 with the 代號\n",
    "\n",
    "product_df_list = []\n",
    "\n",
    "for code in unique_product_code:\n",
    "    temp = df_sum[df_sum['代號']==code].set_index(\"交易日期\")\n",
    "    temp.drop(labels=['代號'], inplace=True, axis=1)\n",
    "    temp.rename(columns={'數量': code}, inplace=True)\n",
    "    product_df_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed = pd.concat(product_df_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed['A'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed['A'].fillna(0).plot(figsize=(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum['交易日期'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_begin = df_sum['交易日期'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we show how to add days on the timestamp\n",
    "\n",
    "from datetime import timedelta\n",
    "    \n",
    "timestamp_plus_one = timestamp_begin + timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_plus_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate timestamp in the dataframe index\n",
    "\n",
    "df_parsed['A'].resample('1D').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed['A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 42 days are added to the pandas series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series model - Let us start :)\n",
    "\n",
    "Let us focus on 代號 A...\n",
    "\n",
    "Using 90 days data to predict the one week sum after one month.\n",
    "\n",
    "For example: using data from 01.01.2018 - 03.31.2018 to predict sum during 05.01.2018 - 05.07.2018\n",
    "\n",
    "Now we have all the tool we need, let us construct the data for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = df_parsed[['A']]\n",
    "df_A = df_A.resample('1D').sum()\n",
    "df_A.fillna(0, inplace=True)  # replace all the NaN with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "train_size = 0.8\n",
    "\n",
    "df_train = df_A[:int(train_size * len(df_A))]\n",
    "df_test = df_A[int(train_size * len(df_A)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "normalizer = MinMaxScaler()\n",
    "\n",
    "df_train_normalized = normalizer.fit_transform(df_train)\n",
    "df_test_normalized = normalizer.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_points = 90\n",
    "future = 30\n",
    "duration = 7\n",
    "\n",
    "X_train = np.array([df_train_normalized[i : i + history_points] for i in range(len(df_train_normalized) - history_points)])\n",
    "y_train = np.array([df_train_normalized[i + history_points + future: i + history_points + future + duration].sum() for i in range(len(df_train_normalized) - history_points - future)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([df_train_normalized[i + history_points + future: i + history_points + future + duration].sum() for i in range(len(df_train_normalized) - history_points - future)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:len(y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# build LSTM model\n",
    "\n",
    "def lstm_model():\n",
    "    tf.random.set_seed(20)\n",
    "    np.random.seed(10)\n",
    "    lstm_input = Input(shape=(history_points, 1), name='lstm_input')\n",
    "\n",
    "    inputs = LSTM(30, name='first_layer')(lstm_input)\n",
    "    inputs = Dense(10)(inputs)\n",
    "    inputs = Dense(1)(inputs)\n",
    "    output = Activation('linear', name='output')(inputs)\n",
    "\n",
    "    model = Model(inputs=lstm_input, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([df_test_normalized[i : i + history_points] for i in range(len(df_test_normalized) - history_points)])\n",
    "y_test = np.array([df_test_normalized[i + history_points + future: i + history_points + future + duration].sum() for i in range(len(df_test_normalized) - history_points - future)])\n",
    "X_test = X_test[:len(y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_model()\n",
    "\n",
    "adam = optimizers.Adam(lr = 0.001)\n",
    "model.compile(optimizer=adam, loss='mse')\n",
    "model.fit(x=X_train, y=y_train, batch_size=4, epochs=5, shuffle=True, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "ax.plot(y_pred, label='LSTM prediction')\n",
    "ax.plot(y_test, label='Ground_truth')\n",
    "\n",
    "ax.set_title(\"Validation set\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,12))\n",
    "\n",
    "ax.plot(y_pred, label='LSTM prediction')\n",
    "ax.plot(y_train, label='Ground_truth')\n",
    "\n",
    "ax.set_title(\"Training set\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model captures something but not response fast enough to the short time movement. Let us see if we can improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A['A_diff'] = df_A.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_A[:int(train_size * len(df_A))].fillna(0)\n",
    "df_test = df_A[int(train_size * len(df_A)):].fillna(0)\n",
    "\n",
    "normalizer = MinMaxScaler()\n",
    "\n",
    "df_train_normalized = normalizer.fit_transform(df_train)\n",
    "df_test_normalized = normalizer.transform(df_test)\n",
    "\n",
    "history_points = 90\n",
    "future = 30\n",
    "duration = 7\n",
    "\n",
    "X_train = np.array([df_train_normalized[i : i + history_points] for i in range(len(df_train_normalized) - history_points)])\n",
    "y_train = np.array([df_train_normalized[i + history_points + future: i + history_points + future + duration, 0].sum() for i in range(len(df_train_normalized) - history_points - future)])\n",
    "X_train = X_train[:len(y_train)]\n",
    "\n",
    "X_test = np.array([df_test_normalized[i : i + history_points] for i in range(len(df_test_normalized) - history_points)])\n",
    "y_test = np.array([df_test_normalized[i + history_points + future: i + history_points + future + duration, 0].sum() for i in range(len(df_test_normalized) - history_points - future)])\n",
    "X_test = X_test[:len(y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model():\n",
    "    tf.random.set_seed(20)\n",
    "    np.random.seed(10)\n",
    "    lstm_input = Input(shape=(history_points, 2), name='lstm_input')\n",
    "\n",
    "    inputs = LSTM(30, name='first_layer')(lstm_input)\n",
    "    inputs = Dense(10)(inputs)\n",
    "    inputs = Dense(1)(inputs)\n",
    "    output = Activation('linear', name='output')(inputs)\n",
    "\n",
    "    model = Model(inputs=lstm_input, outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = lstm_model()\n",
    "\n",
    "adam = optimizers.Adam(lr = 0.001)\n",
    "model.compile(optimizer=adam, loss='mse')\n",
    "model.fit(x=X_train, y=y_train, batch_size=4, epochs=5, shuffle=True, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "ax.plot(y_pred, label='LSTM prediction')\n",
    "ax.plot(y_test, label='Ground_truth')\n",
    "\n",
    "ax.set_title(\"Validation set\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,12))\n",
    "\n",
    "ax.plot(y_pred, label='LSTM prediction')\n",
    "ax.plot(y_train, label='Ground_truth')\n",
    "\n",
    "ax.set_title(\"Training set\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model():\n",
    "    tf.random.set_seed(20)\n",
    "    np.random.seed(10)\n",
    "    lstm_input = Input(shape=(history_points, 2), name='lstm_input')\n",
    "\n",
    "    inputs = LSTM(64, name='first_lstm_layer', return_sequences=True)(lstm_input)\n",
    "    inputs = LSTM(32, name='second_lstm_layer')(inputs)\n",
    "    inputs = Dense(10)(inputs)\n",
    "    inputs = Dense(1)(inputs)\n",
    "    output = Activation('linear', name='output')(inputs)\n",
    "\n",
    "    model = Model(inputs=lstm_input, outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = lstm_model()\n",
    "\n",
    "adam = optimizers.Adam(lr = 0.001)\n",
    "model.compile(optimizer=adam, loss='mse')\n",
    "model.fit(x=X_train, y=y_train, batch_size=4, epochs=5, shuffle=True, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "ax.plot(y_pred, label='LSTM prediction')\n",
    "ax.plot(y_test, label='Ground_truth')\n",
    "\n",
    "ax.set_title(\"Validation set\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,12))\n",
    "\n",
    "ax.plot(y_pred, label='LSTM prediction')\n",
    "ax.plot(y_train, label='Ground_truth')\n",
    "\n",
    "ax.set_title(\"Training set\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.index[0].weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A['weekday'] = df_A.index.weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_A.index.dt.weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdays = [idx.weekday() for idx in df_A.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A['weekday'] = weekdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A[df_A['weekday']==0]['A'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A[df_A['weekday']==1]['A'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A[df_A['weekday']==2]['A'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A[df_A['weekday']==3]['A'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A[df_A['weekday']==4]['A'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A[df_A['weekday']==5]['A'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A[df_A['weekday']==6]['A'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
