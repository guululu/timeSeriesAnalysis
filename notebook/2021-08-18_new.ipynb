{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 預測目標\n",
    "\n",
    "預測六週後一週內的原物料需求量，以作為倉儲調度參考。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd  # python community standard \n",
    "import numpy as np\n",
    "\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from main.utils.utils import time_series_train_test_split, data_normalization, data_preparation\n",
    "from main.model.LSTM_model import lstm_basic_model\n",
    "from main.utils.data import load_data\n",
    "\n",
    "df_parsed = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_A = df_parsed[['A']]\n",
    "df_A = df_A.resample('1D').sum()\n",
    "df_A.fillna(0, inplace=True)\n",
    "\n",
    "df_A['week'] = [idx.week for idx in df_A.index]\n",
    "df_A['year'] = [idx.year for idx in df_A.index]\n",
    "\n",
    "df_A_year_week = df_A.groupby(['week', 'year'], as_index=False)['A'].sum()\n",
    "\n",
    "df_A_year_week.sort_values(by=['year', 'week'], inplace=True)\n",
    "\n",
    "df_A_year_week.reset_index(drop=True, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(df_A_year_week['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df_A_year_week['A'].mean()\n",
    "std = df_A_year_week['A'].std()\n",
    "\n",
    "print(f\"mean = {mean}, std = {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(df_A_year_week['A'])\n",
    "ax.axhline(y=mean, color='g', linestyle='-')\n",
    "ax.axhline(y=mean + std, color='r', linestyle='-')\n",
    "ax.axhline(y=mean - std, color='r', linestyle='-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strong week by week fluctuations. \n",
    "However, from business perspective, extremely accurate weekly consumption prediction is not that relevant. Because excessively ordered material can be left to the future. The two key goals are:\n",
    "\n",
    "1. Make sure there is enough material for consumption.\n",
    "2. Keep the storage reasonably low to reduce the warehouse cost.\n",
    "\n",
    "Therefore, instead of predicting the exact weekly consumption, we predict a smoothed weekly consumption: 50% from the week and 50% from 4 weeks in the future average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A_year_week['A'][:4].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = len(df_A_year_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_weeks_average = [df_A_year_week['A'][i: min((i+4), data_size)].mean() for i in range(data_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A_year_week['A_four_weeks_average'] = four_weeks_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A_year_week['A_target'] = df_A_year_week[['A', 'A_four_weeks_average']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(df_A_year_week['A'], c='b', label='raw data')\n",
    "ax.plot(df_A_year_week['A_target'], c='r', label='processed data')\n",
    "\n",
    "ax.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df_A_year_week['A_target'].mean()\n",
    "std = df_A_year_week['A_target'].std()\n",
    "\n",
    "print(f\"mean = {mean}, std = {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A_year_week['A_diff'] = df_A_year_week['A_target'] - df_A_year_week['A']\n",
    "df_A_year_week['A_diff_cum'] = df_A_year_week['A_diff'].cumsum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(df_A_year_week['A_diff_cum'], c='b')\n",
    "ax.plot(df_A_year_week['A_diff'], c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering Pipeline\n",
    "\n",
    "* history = 14\n",
    "* future = 42\n",
    "* duration = 7\n",
    "* extension = 28\n",
    "\n",
    "Then aggregate the day data to 7-days sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 0.8\n",
    "\n",
    "history = 14\n",
    "future = 42\n",
    "duration = 7\n",
    "extension = 28\n",
    "\n",
    "df_train, df_test = time_series_train_test_split(df_A[['A']], frac=frac)\n",
    "df_train_normalized, df_test_normalized = data_normalization(df_train, df_test)\n",
    "\n",
    "X_train_days = np.array([df_train_normalized[i: i + history] for i in range(len(df_train_normalized) - history - future - extension)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_days.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_data = [ X_train_days[:, i*7:(i+1)*7, :].sum(axis=1, keepdims=True) for i in range(history//7)]\n",
    "X_train_weeks =  np.concatenate(weekly_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(weekly_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_weeks.shape   # 962 rows, 2 weeks in the past, one feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'A'\n",
    "\n",
    "y_train_days = np.array([df_train[target].values[i: i+extension] for i in range(history + future, len(df_train_normalized) - extension)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_days.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_data = np.array([y_train_days[:, i*7:(i+1)*7].sum(axis=1, keepdims=True) for i in range(extension//7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_weeks_mean = weekly_data.mean(axis=0)\n",
    "target_week = weekly_data[0, :, :]\n",
    "\n",
    "fusion_data = np.concatenate([four_weeks_mean, target_week], axis=1).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(target_week, c='b')\n",
    "ax.plot(fusion_data, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "rescaled_fusion_data = scaler.fit_transform(fusion_data.reshape(-1, 1)).reshape(-1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us write a pipeline line to make our life easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_aggregation(df: pd.DataFrame, history: int, future: int, extension: int, duration: int):\n",
    "    \n",
    "    X_days = np.array([df[i: i + history] for i in range(len(df) - history - future - extension)])\n",
    "    weekly_data = [ X_days[:, i*duration:(i+1)*duration, :].sum(axis=1, keepdims=True) for i in range(history//duration)]\n",
    "    X_week =  np.concatenate(weekly_data, axis=1)\n",
    "    \n",
    "    return X_week\n",
    "\n",
    "\n",
    "def target_aggregation(df: pd.DataFrame, history: int, future: int, extension: int, duration: int, target: str):\n",
    "    \n",
    "    y_days = np.array([df[target].values[i: i+extension] for i in range(history + future, len(df) - extension)])\n",
    "    weekly_data = np.array([y_days[:, i*duration:(i+1)*duration].sum(axis=1, keepdims=True) for i in range(extension//duration)])\n",
    "    \n",
    "    four_weeks_mean = weekly_data.mean(axis=0)\n",
    "    target_week = weekly_data[0, :, :]\n",
    "\n",
    "    y_week = np.concatenate([four_weeks_mean, target_week], axis=1).mean(axis=1)\n",
    "    \n",
    "    return y_week\n",
    "\n",
    "\n",
    "def data_transformation(df_train: pd.DataFrame, df_test: pd.DataFrame, history: int, future: int, extension: int, duration: int, target: str):\n",
    "    \n",
    "    df_train_normalized, df_test_normalized = data_normalization(df_train, df_test)\n",
    "    \n",
    "    X_train = feature_aggregation(df_train_normalized, history=history, future=future, extension=extension, duration=duration)\n",
    "    X_test = feature_aggregation(df_test_normalized, history=history, future=future, extension=extension, duration=duration)\n",
    "    \n",
    "    assert (target in df_train.columns) and (target in df_test.columns)\n",
    "    \n",
    "    y_train = target_aggregation(df_train, history=history, future=future, extension=extension, duration=duration, target=target)\n",
    "    y_test = target_aggregation(df_test, history=history, future=future, extension=extension, duration=duration, target=target)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_transformation(df_train, df_test, history=history, future=future, extension=extension, duration=duration, target='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "y_train = scaler.fit_transform(y_train.reshape(-1, 1)).reshape(-1,)\n",
    "y_test = scaler.transform(y_test.reshape(-1, 1)).reshape(-1, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "history_points = 2\n",
    "features = 1\n",
    "\n",
    "model = lstm_basic_model(history_points=history_points, features=features)\n",
    "model.compile(optimizer=optimizers.Adam(lr = 0.001), loss='mse')\n",
    "model.fit(x=X_train, y=y_train, batch_size=4, epochs=5, shuffle=True, validation_data=(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "ax.plot(y_pred, c='b', label='LSTM prediction')\n",
    "ax.plot(y_test, c='r', label='Ground_truth')\n",
    "\n",
    "ax.set_title(\"Validation set\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try add one more external feature: product C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = time_series_train_test_split(df_parsed[['A', 'C']], frac=frac)\n",
    "X_train, X_test, y_train, y_test = data_transformation(df_train, df_test, history=history, future=future, extension=extension, duration=duration, target='A')\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "y_train = scaler.fit_transform(y_train.reshape(-1, 1)).reshape(-1,)\n",
    "y_test = scaler.transform(y_test.reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "history_points = 2\n",
    "features = 2\n",
    "\n",
    "model = lstm_basic_model(history_points=history_points, features=features)\n",
    "model.compile(optimizer=optimizers.Adam(lr = 0.001), loss='mse')\n",
    "model.fit(x=X_train, y=y_train, batch_size=4, epochs=5, shuffle=True, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "ax.plot(y_pred, c='b', label='LSTM prediction')\n",
    "ax.plot(y_test, c='r', label='Ground_truth')\n",
    "\n",
    "ax.set_title(\"Validation set\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we ake more history points? like four weeks\n",
    "\n",
    "history = 28\n",
    "\n",
    "df_train, df_test = time_series_train_test_split(df_parsed[['A']], frac=frac)\n",
    "X_train, X_test, y_train, y_test = data_transformation(df_train, df_test, history=history, future=future, extension=extension, duration=duration, target='A')\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "y_train = scaler.fit_transform(y_train.reshape(-1, 1)).reshape(-1,)\n",
    "y_test = scaler.transform(y_test.reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "history_points = 4\n",
    "features = 1\n",
    "\n",
    "model = lstm_basic_model(history_points=history_points, features=features)\n",
    "model.compile(optimizer=optimizers.Adam(lr = 0.001), loss='mse')\n",
    "model.fit(x=X_train, y=y_train, batch_size=4, epochs=5, shuffle=True, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = 21\n",
    "\n",
    "df_train, df_test = time_series_train_test_split(df_parsed[['A']], frac=frac)\n",
    "X_train, X_test, y_train, y_test = data_transformation(df_train, df_test, history=history, future=future, extension=extension, duration=duration, target='A')\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "y_train = scaler.fit_transform(y_train.reshape(-1, 1)).reshape(-1,)\n",
    "y_test = scaler.transform(y_test.reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "history_points = 3\n",
    "features = 1\n",
    "\n",
    "model = lstm_basic_model(history_points=history_points, features=features)\n",
    "model.compile(optimizer=optimizers.Adam(lr = 0.001), loss='mse')\n",
    "model.fit(x=X_train, y=y_train, batch_size=4, epochs=5, shuffle=True, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model captures something but not response fast enough to the short time movement. Let us see if we can improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MACD(df: pd.DataFrame, period_fast, period_slow, signal, column: str, adjust: bool = True):\n",
    "    \n",
    "    \"\"\"\n",
    "    MACD, MACD Signal and MACD difference.\n",
    "    The MACD Line oscillates above and below the zero line, which is also known as the centerline.\n",
    "    These crossovers signal that the 12-day EMA has crossed the 26-day EMA. The direction, of course, depends on the direction of the moving average cross.\n",
    "    Positive MACD indicates that the 12-day EMA is above the 26-day EMA. Positive values increase as the shorter EMA diverges further from the longer EMA.\n",
    "    This means upside momentum is increasing. Negative MACD values indicates that the 12-day EMA is below the 26-day EMA.\n",
    "    Negative values increase as the shorter EMA diverges further below the longer EMA. This means downside momentum is increasing.\n",
    "    Signal line crossovers are the most common MACD signals. The signal line is a 9-day EMA of the MACD Line.\n",
    "    As a moving average of the indicator, it trails the MACD and makes it easier to spot MACD turns.\n",
    "    A bullish crossover occurs when the MACD turns up and crosses above the signal line.\n",
    "    A bearish crossover occurs when the MACD turns down and crosses below the signal line.\n",
    "    \"\"\"\n",
    "    \n",
    "    EMA_fast = pd.Series(\n",
    "            df[column].ewm(ignore_na=False, span=period_fast, adjust=adjust).mean(),\n",
    "            name=\"EMA_fast\",\n",
    "        )\n",
    "    EMA_slow = pd.Series(\n",
    "        df[column].ewm(ignore_na=False, span=period_slow, adjust=adjust).mean(),\n",
    "        name=\"EMA_slow\",\n",
    "    )\n",
    "    MACD = pd.Series(EMA_fast - EMA_slow, name=f\"{column}_MACD\")\n",
    "    MACD_signal = pd.Series(\n",
    "        MACD.ewm(ignore_na=False, span=signal, adjust=adjust).mean(), name=f\"{column}_SIGNAL\"\n",
    "    )\n",
    "\n",
    "    return pd.concat([MACD, MACD_signal], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_parsed[['A']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MACD = MACD(df,  period_fast=12, period_slow=26, signal=9, column='A')\n",
    "df = pd.concat([df, df_MACD], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=21\n",
    "\n",
    "df_train, df_test = time_series_train_test_split(df, frac=frac)\n",
    "X_train, X_test, y_train, y_test = data_transformation(df_train, df_test, history=history, future=future, extension=extension, duration=duration, target='A')\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "y_train = scaler.fit_transform(y_train.reshape(-1, 1)).reshape(-1,)\n",
    "y_test = scaler.transform(y_test.reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "history_points = 3\n",
    "features = 3\n",
    "\n",
    "model = lstm_basic_model(history_points=history_points, features=features)\n",
    "model.compile(optimizer=optimizers.Adam(lr = 0.001), loss='mse')\n",
    "model.fit(x=X_train, y=y_train, batch_size=4, epochs=5, shuffle=True, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_parsed[['A', 'C']]\n",
    "\n",
    "df = df.resample('1D').sum()\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "df_MACD = MACD(df,  period_fast=12, period_slow=26, signal=9, column='A')\n",
    "df = pd.concat([df, df_MACD], axis=1)\n",
    "# df_MACD = MACD(df,  period_fast=12, period_slow=26, signal=9, column='C')\n",
    "# df = pd.concat([df, df_MACD], axis=1)\n",
    "\n",
    "history=21\n",
    "\n",
    "df_train, df_test = time_series_train_test_split(df, frac=frac)\n",
    "X_train, X_test, y_train, y_test = data_transformation(df_train, df_test, history=history, future=future, extension=extension, duration=duration, target='A')\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "y_train = scaler.fit_transform(y_train.reshape(-1, 1)).reshape(-1,)\n",
    "y_test = scaler.transform(y_test.reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "history_points = 3\n",
    "features = 4\n",
    "\n",
    "model = lstm_basic_model(history_points=history_points, features=features)\n",
    "model.compile(optimizer=optimizers.Adam(lr = 0.001), loss='mse')\n",
    "model.fit(x=X_train, y=y_train, batch_size=4, epochs=5, shuffle=True, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_parsed[['A', 'C']]\n",
    "\n",
    "df = df.resample('1D').sum()\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "df_MACD = MACD(df,  period_fast=12, period_slow=26, signal=9, column='A')\n",
    "df = pd.concat([df, df_MACD], axis=1)\n",
    "df_MACD = MACD(df,  period_fast=12, period_slow=26, signal=9, column='C')\n",
    "df = pd.concat([df, df_MACD], axis=1)\n",
    "\n",
    "history=21\n",
    "\n",
    "df_train, df_test = time_series_train_test_split(df, frac=frac)\n",
    "X_train, X_test, y_train, y_test = data_transformation(df_train, df_test, history=history, future=future, extension=extension, duration=duration, target='A')\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "y_train = scaler.fit_transform(y_train.reshape(-1, 1)).reshape(-1,)\n",
    "y_test = scaler.transform(y_test.reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "history_points = 3\n",
    "features = 6\n",
    "\n",
    "model = lstm_basic_model(history_points=history_points, features=features)\n",
    "model.compile(optimizer=optimizers.Adam(lr = 0.001), loss='mse')\n",
    "model.fit(x=X_train, y=y_train, batch_size=4, epochs=5, shuffle=True, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_parsed[['A', 'C', 'G']]\n",
    "\n",
    "df = df.resample('1D').sum()\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "df_MACD = MACD(df,  period_fast=12, period_slow=26, signal=9, column='A')\n",
    "df = pd.concat([df, df_MACD], axis=1)\n",
    "df_MACD = MACD(df,  period_fast=12, period_slow=26, signal=9, column='C')\n",
    "df = pd.concat([df, df_MACD], axis=1)\n",
    "df_MACD = MACD(df,  period_fast=12, period_slow=26, signal=9, column='G')\n",
    "df = pd.concat([df, df_MACD], axis=1)\n",
    "\n",
    "history=21\n",
    "\n",
    "df_train, df_test = time_series_train_test_split(df, frac=frac)\n",
    "X_train, X_test, y_train, y_test = data_transformation(df_train, df_test, history=history, future=future, extension=extension, duration=duration, target='A')\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "y_train = scaler.fit_transform(y_train.reshape(-1, 1)).reshape(-1,)\n",
    "y_test = scaler.transform(y_test.reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "history_points = 3\n",
    "features = 9\n",
    "\n",
    "model = lstm_basic_model(history_points=history_points, features=features)\n",
    "model.compile(optimizer=optimizers.Adam(lr = 0.001), loss='mse')\n",
    "model.fit(x=X_train, y=y_train, batch_size=4, epochs=5, shuffle=True, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
